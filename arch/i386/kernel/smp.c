multiline_comment|/*&n; *&t;Intel SMP support routines.&n; *&n; *&t;(c) 1995 Alan Cox, Building #3 &lt;alan@redhat.com&gt;&n; *&t;(c) 1998-99 Ingo Molnar &lt;mingo@redhat.com&gt;&n; *&n; *&t;This code is released under the GNU public license version 2 or&n; *&t;later.&n; */
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
macro_line|#include &lt;linux/irq.h&gt;
macro_line|#include &lt;linux/delay.h&gt;
macro_line|#include &lt;linux/mc146818rtc.h&gt;
macro_line|#include &lt;asm/mtrr.h&gt;
multiline_comment|/*&n; *&t;Some notes on processor bugs:&n; *&n; *&t;Pentium, Pentium Pro, II, III (and all CPUs) have bugs.&n; *&t;The Linux implications for SMP are handled as follows:&n; *&n; *&t;Pentium III / [Xeon]&n; *&t;&t;None of the E1AP-E3AP erratas are visible to the user.&n; *&n; *&t;E1AP.&t;see PII A1AP&n; *&t;E2AP.&t;see PII A2AP&n; *&t;E3AP.&t;see PII A3AP&n; *&n; *&t;Pentium II / [Xeon]&n; *&t;&t;None of the A1AP-A3AP erratas are visible to the user.&n; *&n; *&t;A1AP.&t;see PPro 1AP&n; *&t;A2AP.&t;see PPro 2AP&n; *&t;A3AP.&t;see PPro 7AP&n; *&n; *&t;Pentium Pro&n; *&t;&t;None of 1AP-9AP erratas are visible to the normal user,&n; *&t;except occasional delivery of &squot;spurious interrupt&squot; as trap #15.&n; *&t;This is very rare and a non-problem.&n; *&n; *&t;1AP.&t;Linux maps APIC as non-cacheable&n; *&t;2AP.&t;worked around in hardware&n; *&t;3AP.&t;fixed in C0 and above steppings microcode update.&n; *&t;&t;Linux does not use excessive STARTUP_IPIs.&n; *&t;4AP.&t;worked around in hardware&n; *&t;5AP.&t;symmetric IO mode (normal Linux operation) not affected.&n; *&t;&t;&squot;noapic&squot; mode has vector 0xf filled out properly.&n; *&t;6AP.&t;&squot;noapic&squot; mode might be affected - fixed in later steppings&n; *&t;7AP.&t;We do not assume writes to the LVT deassering IRQs&n; *&t;8AP.&t;We do not enable low power mode (deep sleep) during MP bootup&n; *&t;9AP.&t;We do not use mixed mode&n; *&n; *&t;Pentium&n; *&t;&t;There is a marginal case where REP MOVS on 100MHz SMP&n; *&t;machines with B stepping processors can fail. XXX should provide&n; *&t;an L1cache=Writethrough or L1cache=off option.&n; *&n; *&t;&t;B stepping CPUs may hang. There are hardware work arounds&n; *&t;for this. We warn about it in case your board doesnt have the work&n; *&t;arounds. Basically thats so I can tell anyone with a B stepping&n; *&t;CPU and SMP problems &quot;tough&quot;.&n; *&n; *&t;Specific items [From Pentium Processor Specification Update]&n; *&n; *&t;1AP.&t;Linux doesn&squot;t use remote read&n; *&t;2AP.&t;Linux doesn&squot;t trust APIC errors&n; *&t;3AP.&t;We work around this&n; *&t;4AP.&t;Linux never generated 3 interrupts of the same priority&n; *&t;&t;to cause a lost local interrupt.&n; *&t;5AP.&t;Remote read is never used&n; *&t;6AP.&t;not affected - worked around in hardware&n; *&t;7AP.&t;not affected - worked around in hardware&n; *&t;8AP.&t;worked around in hardware - we get explicit CS errors if not&n; *&t;9AP.&t;only &squot;noapic&squot; mode affected. Might generate spurious&n; *&t;&t;interrupts, we log only the first one and count the&n; *&t;&t;rest silently.&n; *&t;10AP.&t;not affected - worked around in hardware&n; *&t;11AP.&t;Linux reads the APIC between writes to avoid this, as per&n; *&t;&t;the documentation. Make sure you preserve this as it affects&n; *&t;&t;the C stepping chips too.&n; *&t;12AP.&t;not affected - worked around in hardware&n; *&t;13AP.&t;not affected - worked around in hardware&n; *&t;14AP.&t;we always deassert INIT during bootup&n; *&t;15AP.&t;not affected - worked around in hardware&n; *&t;16AP.&t;not affected - worked around in hardware&n; *&t;17AP.&t;not affected - worked around in hardware&n; *&t;18AP.&t;not affected - worked around in hardware&n; *&t;19AP.&t;not affected - worked around in BIOS&n; *&n; *&t;If this sounds worrying believe me these bugs are either ___RARE___,&n; *&t;or are signal timing bugs worked around in hardware and there&squot;s&n; *&t;about nothing of note with C stepping upwards.&n; */
multiline_comment|/* The &squot;big kernel lock&squot; */
DECL|variable|kernel_flag
id|spinlock_t
id|kernel_flag
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
DECL|variable|smp_invalidate_needed
r_volatile
r_int
r_int
id|smp_invalidate_needed
suffix:semicolon
multiline_comment|/*&n; * the following functions deal with sending IPIs between CPUs.&n; *&n; * We use &squot;broadcast&squot;, CPU-&gt;CPU IPIs and self-IPIs too.&n; */
DECL|variable|cached_APIC_ICR
r_static
r_int
r_int
id|cached_APIC_ICR
suffix:semicolon
DECL|variable|cached_APIC_ICR2
r_static
r_int
r_int
id|cached_APIC_ICR2
suffix:semicolon
multiline_comment|/*&n; * Caches reserved bits, APIC reads are (mildly) expensive&n; * and force otherwise unnecessary CPU synchronization.&n; *&n; * (We could cache other APIC registers too, but these are the&n; * main ones used in RL.)&n; */
DECL|macro|slow_ICR
mdefine_line|#define slow_ICR (apic_read(APIC_ICR) &amp; ~0xFDFFF)
DECL|macro|slow_ICR2
mdefine_line|#define slow_ICR2 (apic_read(APIC_ICR2) &amp; 0x00FFFFFF)
DECL|function|cache_APIC_registers
r_void
id|cache_APIC_registers
(paren
r_void
)paren
(brace
id|cached_APIC_ICR
op_assign
id|slow_ICR
suffix:semicolon
id|cached_APIC_ICR2
op_assign
id|slow_ICR2
suffix:semicolon
id|mb
c_func
(paren
)paren
suffix:semicolon
)brace
DECL|function|__get_ICR
r_static
r_inline
r_int
r_int
id|__get_ICR
(paren
r_void
)paren
(brace
macro_line|#if FORCE_READ_AROUND_WRITE
multiline_comment|/*&n;&t; * Wait for the APIC to become ready - this should never occur. It&squot;s&n;&t; * a debugging check really.&n;&t; */
r_int
id|count
op_assign
l_int|0
suffix:semicolon
r_int
r_int
id|cfg
suffix:semicolon
r_while
c_loop
(paren
id|count
OL
l_int|1000
)paren
(brace
id|cfg
op_assign
id|slow_ICR
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
(paren
id|cfg
op_amp
(paren
l_int|1
op_lshift
l_int|12
)paren
)paren
)paren
r_return
id|cfg
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;CPU #%d: ICR still busy [%08x]&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
comma
id|cfg
)paren
suffix:semicolon
id|irq_err_count
op_increment
suffix:semicolon
id|count
op_increment
suffix:semicolon
id|udelay
c_func
(paren
l_int|10
)paren
suffix:semicolon
)brace
id|printk
c_func
(paren
l_string|&quot;CPU #%d: previous IPI still not cleared after 10mS&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
r_return
id|cfg
suffix:semicolon
macro_line|#else
r_return
id|cached_APIC_ICR
suffix:semicolon
macro_line|#endif
)brace
DECL|function|__get_ICR2
r_static
r_inline
r_int
r_int
id|__get_ICR2
(paren
r_void
)paren
(brace
macro_line|#if FORCE_READ_AROUND_WRITE
r_return
id|slow_ICR2
suffix:semicolon
macro_line|#else
r_return
id|cached_APIC_ICR2
suffix:semicolon
macro_line|#endif
)brace
DECL|macro|LOGICAL_DELIVERY
mdefine_line|#define LOGICAL_DELIVERY 1
DECL|function|__prepare_ICR
r_static
r_inline
r_int
id|__prepare_ICR
(paren
r_int
r_int
id|shortcut
comma
r_int
id|vector
)paren
(brace
r_int
r_int
id|cfg
suffix:semicolon
id|cfg
op_assign
id|__get_ICR
c_func
(paren
)paren
suffix:semicolon
id|cfg
op_or_assign
id|APIC_DEST_DM_FIXED
op_or
id|shortcut
op_or
id|vector
macro_line|#if LOGICAL_DELIVERY
op_or
id|APIC_DEST_LOGICAL
macro_line|#endif
suffix:semicolon
r_return
id|cfg
suffix:semicolon
)brace
DECL|function|__prepare_ICR2
r_static
r_inline
r_int
id|__prepare_ICR2
(paren
r_int
r_int
id|dest
)paren
(brace
r_int
r_int
id|cfg
suffix:semicolon
id|cfg
op_assign
id|__get_ICR2
c_func
(paren
)paren
suffix:semicolon
macro_line|#if LOGICAL_DELIVERY
id|cfg
op_or_assign
id|SET_APIC_DEST_FIELD
c_func
(paren
(paren
l_int|1
op_lshift
id|dest
)paren
)paren
suffix:semicolon
macro_line|#else
id|cfg
op_or_assign
id|SET_APIC_DEST_FIELD
c_func
(paren
id|dest
)paren
suffix:semicolon
macro_line|#endif
r_return
id|cfg
suffix:semicolon
)brace
DECL|function|__send_IPI_shortcut
r_static
r_inline
r_void
id|__send_IPI_shortcut
c_func
(paren
r_int
r_int
id|shortcut
comma
r_int
id|vector
)paren
(brace
r_int
r_int
id|cfg
suffix:semicolon
multiline_comment|/*&n; * Subtle. In the case of the &squot;never do double writes&squot; workaround we&n; * have to lock out interrupts to be safe. Otherwise it&squot;s just one&n; * single atomic write to the APIC, no need for cli/sti.&n; */
macro_line|#if FORCE_READ_AROUND_WRITE
r_int
r_int
id|flags
suffix:semicolon
id|__save_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__cli
c_func
(paren
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/*&n;&t; * No need to touch the target chip field&n;&t; */
id|cfg
op_assign
id|__prepare_ICR
c_func
(paren
id|shortcut
comma
id|vector
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Send the IPI. The write to APIC_ICR fires this off.&n;&t; */
id|apic_write
c_func
(paren
id|APIC_ICR
comma
id|cfg
)paren
suffix:semicolon
macro_line|#if FORCE_READ_AROUND_WRITE
id|__restore_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
macro_line|#endif
)brace
DECL|function|send_IPI_allbutself
r_static
r_inline
r_void
id|send_IPI_allbutself
c_func
(paren
r_int
id|vector
)paren
(brace
multiline_comment|/*&n;&t; * if there are no other CPUs in the system then&n;&t; * we get an APIC send error if we try to broadcast.&n;&t; * thus we have to avoid sending IPIs in this case.&n;&t; */
r_if
c_cond
(paren
id|smp_num_cpus
OG
l_int|1
)paren
id|__send_IPI_shortcut
c_func
(paren
id|APIC_DEST_ALLBUT
comma
id|vector
)paren
suffix:semicolon
)brace
DECL|function|send_IPI_all
r_static
r_inline
r_void
id|send_IPI_all
c_func
(paren
r_int
id|vector
)paren
(brace
id|__send_IPI_shortcut
c_func
(paren
id|APIC_DEST_ALLINC
comma
id|vector
)paren
suffix:semicolon
)brace
DECL|function|send_IPI_self
r_void
id|send_IPI_self
c_func
(paren
r_int
id|vector
)paren
(brace
id|__send_IPI_shortcut
c_func
(paren
id|APIC_DEST_SELF
comma
id|vector
)paren
suffix:semicolon
)brace
DECL|function|send_IPI_single
r_static
r_inline
r_void
id|send_IPI_single
c_func
(paren
r_int
id|dest
comma
r_int
id|vector
)paren
(brace
r_int
r_int
id|cfg
suffix:semicolon
macro_line|#if FORCE_READ_AROUND_WRITE
r_int
r_int
id|flags
suffix:semicolon
id|__save_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__cli
c_func
(paren
)paren
suffix:semicolon
macro_line|#endif
multiline_comment|/*&n;&t; * prepare target chip field&n;&t; */
id|cfg
op_assign
id|__prepare_ICR2
c_func
(paren
id|dest
)paren
suffix:semicolon
id|apic_write
c_func
(paren
id|APIC_ICR2
comma
id|cfg
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * program the ICR &n;&t; */
id|cfg
op_assign
id|__prepare_ICR
c_func
(paren
l_int|0
comma
id|vector
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Send the IPI. The write to APIC_ICR fires this off.&n;&t; */
id|apic_write
c_func
(paren
id|APIC_ICR
comma
id|cfg
)paren
suffix:semicolon
macro_line|#if FORCE_READ_AROUND_WRITE
id|__restore_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
macro_line|#endif
)brace
multiline_comment|/*&n; * This is fraught with deadlocks. Probably the situation is not that&n; * bad as in the early days of SMP, so we might ease some of the&n; * paranoia here.&n; */
DECL|function|flush_tlb_others
r_static
r_void
id|flush_tlb_others
c_func
(paren
r_int
r_int
id|cpumask
)paren
(brace
r_int
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
r_int
id|stuck
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
multiline_comment|/*&n;&t; * it&squot;s important that we do not generate any APIC traffic&n;&t; * until the AP CPUs have booted up!&n;&t; */
id|cpumask
op_and_assign
id|cpu_online_map
suffix:semicolon
r_if
c_cond
(paren
id|cpumask
)paren
(brace
id|atomic_set_mask
c_func
(paren
id|cpumask
comma
op_amp
id|smp_invalidate_needed
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * Processors spinning on some lock with IRQs disabled&n;&t;&t; * will see this IRQ late. The smp_invalidate_needed&n;&t;&t; * map will ensure they don&squot;t do a spurious flush tlb&n;&t;&t; * or miss one.&n;&t;&t; */
id|__save_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__cli
c_func
(paren
)paren
suffix:semicolon
id|send_IPI_allbutself
c_func
(paren
id|INVALIDATE_TLB_VECTOR
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * Spin waiting for completion&n;&t;&t; */
id|stuck
op_assign
l_int|50000000
suffix:semicolon
r_while
c_loop
(paren
id|smp_invalidate_needed
)paren
(brace
multiline_comment|/*&n;&t;&t;&t; * Take care of &quot;crossing&quot; invalidates&n;&t;&t;&t; */
r_if
c_cond
(paren
id|test_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_invalidate_needed
)paren
)paren
(brace
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|current-&gt;mm
suffix:semicolon
id|clear_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_invalidate_needed
)paren
suffix:semicolon
r_if
c_cond
(paren
id|mm
)paren
id|atomic_set_mask
c_func
(paren
l_int|1
op_lshift
id|cpu
comma
op_amp
id|mm-&gt;cpu_vm_mask
)paren
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
)brace
op_decrement
id|stuck
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|stuck
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;stuck on TLB IPI wait (CPU#%d)&bslash;n&quot;
comma
id|cpu
)paren
suffix:semicolon
r_break
suffix:semicolon
)brace
)brace
id|__restore_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; *&t;Smarter SMP flushing macros. &n; *&t;&t;c/o Linus Torvalds.&n; *&n; *&t;These mean you can really definitely utterly forget about&n; *&t;writing to user space from interrupts. (Its not allowed anyway).&n; */
DECL|function|flush_tlb_current_task
r_void
id|flush_tlb_current_task
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|vm_mask
op_assign
l_int|1
op_lshift
id|current-&gt;processor
suffix:semicolon
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|current-&gt;mm
suffix:semicolon
r_int
r_int
id|cpu_mask
op_assign
id|mm-&gt;cpu_vm_mask
op_amp
op_complement
id|vm_mask
suffix:semicolon
id|mm-&gt;cpu_vm_mask
op_assign
id|vm_mask
suffix:semicolon
id|flush_tlb_others
c_func
(paren
id|cpu_mask
)paren
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
)brace
DECL|function|flush_tlb_mm
r_void
id|flush_tlb_mm
c_func
(paren
r_struct
id|mm_struct
op_star
id|mm
)paren
(brace
r_int
r_int
id|vm_mask
op_assign
l_int|1
op_lshift
id|current-&gt;processor
suffix:semicolon
r_int
r_int
id|cpu_mask
op_assign
id|mm-&gt;cpu_vm_mask
op_amp
op_complement
id|vm_mask
suffix:semicolon
id|mm-&gt;cpu_vm_mask
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|current-&gt;active_mm
op_eq
id|mm
)paren
(brace
id|mm-&gt;cpu_vm_mask
op_assign
id|vm_mask
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
)brace
id|flush_tlb_others
c_func
(paren
id|cpu_mask
)paren
suffix:semicolon
)brace
DECL|function|flush_tlb_page
r_void
id|flush_tlb_page
c_func
(paren
r_struct
id|vm_area_struct
op_star
id|vma
comma
r_int
r_int
id|va
)paren
(brace
r_int
r_int
id|vm_mask
op_assign
l_int|1
op_lshift
id|current-&gt;processor
suffix:semicolon
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|vma-&gt;vm_mm
suffix:semicolon
r_int
r_int
id|cpu_mask
op_assign
id|mm-&gt;cpu_vm_mask
op_amp
op_complement
id|vm_mask
suffix:semicolon
id|mm-&gt;cpu_vm_mask
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|current-&gt;active_mm
op_eq
id|mm
)paren
(brace
id|__flush_tlb_one
c_func
(paren
id|va
)paren
suffix:semicolon
id|mm-&gt;cpu_vm_mask
op_assign
id|vm_mask
suffix:semicolon
)brace
id|flush_tlb_others
c_func
(paren
id|cpu_mask
)paren
suffix:semicolon
)brace
DECL|function|flush_tlb_all
r_void
id|flush_tlb_all
c_func
(paren
r_void
)paren
(brace
id|flush_tlb_others
c_func
(paren
op_complement
(paren
l_int|1
op_lshift
id|current-&gt;processor
)paren
)paren
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * this function sends a &squot;reschedule&squot; IPI to another CPU.&n; * it goes straight through and wastes no time serializing&n; * anything. Worst case is that we lose a reschedule ...&n; */
DECL|function|smp_send_reschedule
r_void
id|smp_send_reschedule
c_func
(paren
r_int
id|cpu
)paren
(brace
id|send_IPI_single
c_func
(paren
id|cpu
comma
id|RESCHEDULE_VECTOR
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Structure and data for smp_call_function(). This is designed to minimise&n; * static memory requirements. It also looks cleaner.&n; */
DECL|struct|call_data_struct
r_static
r_volatile
r_struct
id|call_data_struct
(brace
DECL|member|func
r_void
(paren
op_star
id|func
)paren
(paren
r_void
op_star
id|info
)paren
suffix:semicolon
DECL|member|info
r_void
op_star
id|info
suffix:semicolon
DECL|member|started
id|atomic_t
id|started
suffix:semicolon
DECL|member|finished
id|atomic_t
id|finished
suffix:semicolon
DECL|member|wait
r_int
id|wait
suffix:semicolon
DECL|variable|call_data
)brace
op_star
id|call_data
op_assign
l_int|NULL
suffix:semicolon
multiline_comment|/*&n; * this function sends a &squot;generic call function&squot; IPI to all other CPUs&n; * in the system.&n; */
DECL|function|smp_call_function
r_int
id|smp_call_function
(paren
r_void
(paren
op_star
id|func
)paren
(paren
r_void
op_star
id|info
)paren
comma
r_void
op_star
id|info
comma
r_int
id|nonatomic
comma
r_int
id|wait
)paren
multiline_comment|/*&n; * [SUMMARY] Run a function on all other CPUs.&n; * &lt;func&gt; The function to run. This must be fast and non-blocking.&n; * &lt;info&gt; An arbitrary pointer to pass to the function.&n; * &lt;nonatomic&gt; If true, we might schedule away to lock the mutex&n; * &lt;wait&gt; If true, wait (atomically) until function has completed on other CPUs.&n; * [RETURNS] 0 on success, else a negative status code. Does not return until&n; * remote CPUs are nearly ready to execute &lt;&lt;func&gt;&gt; or are or have executed.&n; */
(brace
r_struct
id|call_data_struct
id|data
suffix:semicolon
r_int
id|ret
comma
id|cpus
op_assign
id|smp_num_cpus
op_minus
l_int|1
suffix:semicolon
r_static
id|DECLARE_MUTEX
c_func
(paren
id|lock
)paren
suffix:semicolon
r_int
r_int
id|timeout
suffix:semicolon
r_if
c_cond
(paren
id|nonatomic
)paren
id|down
c_func
(paren
op_amp
id|lock
)paren
suffix:semicolon
r_else
r_if
c_cond
(paren
id|down_trylock
c_func
(paren
op_amp
id|lock
)paren
)paren
r_return
op_minus
id|EBUSY
suffix:semicolon
r_if
c_cond
(paren
id|call_data
)paren
singleline_comment|// temporary debugging check
id|BUG
c_func
(paren
)paren
suffix:semicolon
id|call_data
op_assign
op_amp
id|data
suffix:semicolon
id|data.func
op_assign
id|func
suffix:semicolon
id|data.info
op_assign
id|info
suffix:semicolon
id|atomic_set
c_func
(paren
op_amp
id|data.started
comma
l_int|0
)paren
suffix:semicolon
id|data.wait
op_assign
id|wait
suffix:semicolon
r_if
c_cond
(paren
id|wait
)paren
id|atomic_set
c_func
(paren
op_amp
id|data.finished
comma
l_int|0
)paren
suffix:semicolon
id|mb
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Send a message to all other CPUs and wait for them to respond */
id|send_IPI_allbutself
c_func
(paren
id|CALL_FUNCTION_VECTOR
)paren
suffix:semicolon
multiline_comment|/* Wait for response */
id|timeout
op_assign
id|jiffies
op_plus
id|HZ
suffix:semicolon
r_while
c_loop
(paren
(paren
id|atomic_read
c_func
(paren
op_amp
id|data.started
)paren
op_ne
id|cpus
)paren
op_logical_and
id|time_before
c_func
(paren
id|jiffies
comma
id|timeout
)paren
)paren
id|barrier
c_func
(paren
)paren
suffix:semicolon
id|ret
op_assign
op_minus
id|ETIMEDOUT
suffix:semicolon
r_if
c_cond
(paren
id|atomic_read
c_func
(paren
op_amp
id|data.started
)paren
op_ne
id|cpus
)paren
r_goto
id|out
suffix:semicolon
id|ret
op_assign
l_int|0
suffix:semicolon
r_if
c_cond
(paren
id|wait
)paren
r_while
c_loop
(paren
id|atomic_read
c_func
(paren
op_amp
id|data.finished
)paren
op_ne
id|cpus
)paren
id|barrier
c_func
(paren
)paren
suffix:semicolon
id|out
suffix:colon
id|call_data
op_assign
l_int|NULL
suffix:semicolon
id|up
c_func
(paren
op_amp
id|lock
)paren
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|function|stop_this_cpu
r_static
r_void
id|stop_this_cpu
(paren
r_void
op_star
id|dummy
)paren
(brace
multiline_comment|/*&n;&t; * Remove this CPU:&n;&t; */
id|clear_bit
c_func
(paren
id|smp_processor_id
c_func
(paren
)paren
comma
op_amp
id|cpu_online_map
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpu_data
(braket
id|smp_processor_id
c_func
(paren
)paren
)braket
dot
id|hlt_works_ok
)paren
r_for
c_loop
(paren
suffix:semicolon
suffix:semicolon
)paren
(brace
id|__asm__
c_func
(paren
l_string|&quot;hlt&quot;
)paren
suffix:semicolon
)brace
r_for
c_loop
(paren
suffix:semicolon
suffix:semicolon
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * this function calls the &squot;stop&squot; function on all other CPUs in the system.&n; */
DECL|function|smp_send_stop
r_void
id|smp_send_stop
c_func
(paren
r_void
)paren
(brace
id|smp_call_function
c_func
(paren
id|stop_this_cpu
comma
l_int|NULL
comma
l_int|1
comma
l_int|0
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Reschedule call back. Nothing to do,&n; * all the work is done automatically when&n; * we return from the interrupt.&n; */
DECL|function|smp_reschedule_interrupt
id|asmlinkage
r_void
id|smp_reschedule_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_APIC_irq
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Invalidate call-back.&n; *&n; * Mark the CPU as a VM user if there is a active&n; * thread holding on to an mm at this time. This&n; * allows us to optimize CPU cross-calls even in the&n; * presense of lazy TLB handling.&n; */
DECL|function|smp_invalidate_interrupt
id|asmlinkage
r_void
id|smp_invalidate_interrupt
c_func
(paren
r_void
)paren
(brace
r_struct
id|task_struct
op_star
id|tsk
op_assign
id|current
suffix:semicolon
r_int
r_int
id|cpu
op_assign
id|tsk-&gt;processor
suffix:semicolon
r_if
c_cond
(paren
id|test_and_clear_bit
c_func
(paren
id|cpu
comma
op_amp
id|smp_invalidate_needed
)paren
)paren
(brace
r_struct
id|mm_struct
op_star
id|mm
op_assign
id|tsk-&gt;mm
suffix:semicolon
r_if
c_cond
(paren
id|mm
)paren
id|atomic_set_mask
c_func
(paren
l_int|1
op_lshift
id|cpu
comma
op_amp
id|mm-&gt;cpu_vm_mask
)paren
suffix:semicolon
id|local_flush_tlb
c_func
(paren
)paren
suffix:semicolon
)brace
id|ack_APIC_irq
c_func
(paren
)paren
suffix:semicolon
)brace
DECL|function|smp_call_function_interrupt
id|asmlinkage
r_void
id|smp_call_function_interrupt
c_func
(paren
r_void
)paren
(brace
r_void
(paren
op_star
id|func
)paren
(paren
r_void
op_star
id|info
)paren
op_assign
id|call_data-&gt;func
suffix:semicolon
r_void
op_star
id|info
op_assign
id|call_data-&gt;info
suffix:semicolon
r_int
id|wait
op_assign
id|call_data-&gt;wait
suffix:semicolon
id|ack_APIC_irq
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Notify initiating CPU that I&squot;ve grabbed the data and am&n;&t; * about to execute the function&n;&t; */
id|atomic_inc
c_func
(paren
op_amp
id|call_data-&gt;started
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * At this point the structure may be out of scope unless wait==1&n;&t; */
(paren
op_star
id|func
)paren
(paren
id|info
)paren
suffix:semicolon
r_if
c_cond
(paren
id|wait
)paren
id|atomic_inc
c_func
(paren
op_amp
id|call_data-&gt;finished
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * This interrupt should _never_ happen with our APIC/SMP architecture&n; */
DECL|function|smp_spurious_interrupt
id|asmlinkage
r_void
id|smp_spurious_interrupt
c_func
(paren
r_void
)paren
(brace
id|ack_APIC_irq
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* see sw-dev-man vol 3, chapter 7.4.13.5 */
id|printk
c_func
(paren
l_string|&quot;spurious APIC interrupt on CPU#%d, should never happen.&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * This interrupt should never happen with our APIC/SMP architecture&n; */
DECL|variable|err_lock
r_static
id|spinlock_t
id|err_lock
suffix:semicolon
DECL|function|smp_error_interrupt
id|asmlinkage
r_void
id|smp_error_interrupt
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|v
suffix:semicolon
id|spin_lock
c_func
(paren
op_amp
id|err_lock
)paren
suffix:semicolon
id|v
op_assign
id|apic_read
c_func
(paren
id|APIC_ESR
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;APIC error interrupt on CPU#%d, should never happen.&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;... APIC ESR0: %08lx&bslash;n&quot;
comma
id|v
)paren
suffix:semicolon
id|apic_write
c_func
(paren
id|APIC_ESR
comma
l_int|0
)paren
suffix:semicolon
id|v
op_assign
id|apic_read
c_func
(paren
id|APIC_ESR
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;... APIC ESR1: %08lx&bslash;n&quot;
comma
id|v
)paren
suffix:semicolon
id|ack_APIC_irq
c_func
(paren
)paren
suffix:semicolon
id|irq_err_count
op_increment
suffix:semicolon
id|spin_unlock
c_func
(paren
op_amp
id|err_lock
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * This part sets up the APIC 32 bit clock in LVTT1, with HZ interrupts&n; * per second. We assume that the caller has already set up the local&n; * APIC.&n; *&n; * The APIC timer is not exactly sync with the external timer chip, it&n; * closely follows bus clocks.&n; */
DECL|variable|prof_multiplier
r_int
id|prof_multiplier
(braket
id|NR_CPUS
)braket
op_assign
(brace
l_int|1
comma
)brace
suffix:semicolon
DECL|variable|prof_old_multiplier
r_int
id|prof_old_multiplier
(braket
id|NR_CPUS
)braket
op_assign
(brace
l_int|1
comma
)brace
suffix:semicolon
DECL|variable|prof_counter
r_int
id|prof_counter
(braket
id|NR_CPUS
)braket
op_assign
(brace
l_int|1
comma
)brace
suffix:semicolon
multiline_comment|/*&n; * The timer chip is already set up at HZ interrupts per second here,&n; * but we do not accept timer interrupts yet. We only allow the BP&n; * to calibrate.&n; */
DECL|function|get_8254_timer_count
r_static
r_int
r_int
id|__init
id|get_8254_timer_count
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|count
suffix:semicolon
id|outb_p
c_func
(paren
l_int|0x00
comma
l_int|0x43
)paren
suffix:semicolon
id|count
op_assign
id|inb_p
c_func
(paren
l_int|0x40
)paren
suffix:semicolon
id|count
op_or_assign
id|inb_p
c_func
(paren
l_int|0x40
)paren
op_lshift
l_int|8
suffix:semicolon
r_return
id|count
suffix:semicolon
)brace
DECL|function|wait_8254_wraparound
r_void
id|__init
id|wait_8254_wraparound
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|curr_count
comma
id|prev_count
op_assign
op_complement
l_int|0
suffix:semicolon
r_int
id|delta
suffix:semicolon
id|curr_count
op_assign
id|get_8254_timer_count
c_func
(paren
)paren
suffix:semicolon
r_do
(brace
id|prev_count
op_assign
id|curr_count
suffix:semicolon
id|curr_count
op_assign
id|get_8254_timer_count
c_func
(paren
)paren
suffix:semicolon
id|delta
op_assign
id|curr_count
op_minus
id|prev_count
suffix:semicolon
multiline_comment|/*&n;&t; * This limit for delta seems arbitrary, but it isn&squot;t, it&squot;s&n;&t; * slightly above the level of error a buggy Mercury/Neptune&n;&t; * chipset timer can cause.&n;&t; */
)brace
r_while
c_loop
(paren
id|delta
OL
l_int|300
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * This function sets up the local APIC timer, with a timeout of&n; * &squot;clocks&squot; APIC bus clock. During calibration we actually call&n; * this function twice on the boot CPU, once with a bogus timeout&n; * value, second time for real. The other (noncalibrating) CPUs&n; * call this function only once, with the real, calibrated value.&n; *&n; * We do reads before writes even if unnecessary, to get around the&n; * P5 APIC double write bug.&n; */
DECL|macro|APIC_DIVISOR
mdefine_line|#define APIC_DIVISOR 16
DECL|function|__setup_APIC_LVTT
r_void
id|__setup_APIC_LVTT
c_func
(paren
r_int
r_int
id|clocks
)paren
(brace
r_int
r_int
id|lvtt1_value
comma
id|tmp_value
suffix:semicolon
id|tmp_value
op_assign
id|apic_read
c_func
(paren
id|APIC_LVTT
)paren
suffix:semicolon
id|lvtt1_value
op_assign
id|SET_APIC_TIMER_BASE
c_func
(paren
id|APIC_TIMER_BASE_DIV
)paren
op_or
id|APIC_LVT_TIMER_PERIODIC
op_or
id|LOCAL_TIMER_VECTOR
suffix:semicolon
id|apic_write
c_func
(paren
id|APIC_LVTT
comma
id|lvtt1_value
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Divide PICLK by 16&n;&t; */
id|tmp_value
op_assign
id|apic_read
c_func
(paren
id|APIC_TDCR
)paren
suffix:semicolon
id|apic_write
c_func
(paren
id|APIC_TDCR
comma
(paren
id|tmp_value
op_amp
op_complement
(paren
id|APIC_TDR_DIV_1
op_or
id|APIC_TDR_DIV_TMBASE
)paren
)paren
op_or
id|APIC_TDR_DIV_16
)paren
suffix:semicolon
id|tmp_value
op_assign
id|apic_read
c_func
(paren
id|APIC_TMICT
)paren
suffix:semicolon
id|apic_write
c_func
(paren
id|APIC_TMICT
comma
id|clocks
op_div
id|APIC_DIVISOR
)paren
suffix:semicolon
)brace
DECL|function|setup_APIC_timer
r_void
id|setup_APIC_timer
c_func
(paren
r_void
op_star
id|data
)paren
(brace
r_int
r_int
id|clocks
op_assign
(paren
r_int
r_int
)paren
id|data
comma
id|slice
comma
id|t0
comma
id|t1
comma
id|nr
suffix:semicolon
r_int
r_int
id|flags
suffix:semicolon
r_int
id|delta
suffix:semicolon
id|__save_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__sti
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * ok, Intel has some smart code in their APIC that knows&n;&t; * if a CPU was in &squot;hlt&squot; lowpower mode, and this increases&n;&t; * its APIC arbitration priority. To avoid the external timer&n;&t; * IRQ APIC event being in synchron with the APIC clock we&n;&t; * introduce an interrupt skew to spread out timer events.&n;&t; *&n;&t; * The number of slices within a &squot;big&squot; timeslice is smp_num_cpus+1&n;&t; */
id|slice
op_assign
id|clocks
op_div
(paren
id|smp_num_cpus
op_plus
l_int|1
)paren
suffix:semicolon
id|nr
op_assign
id|cpu_number_map
(braket
id|smp_processor_id
c_func
(paren
)paren
)braket
op_plus
l_int|1
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;cpu: %d, clocks: %d, slice: %d, nr: %d.&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
comma
id|clocks
comma
id|slice
comma
id|nr
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Wait for IRQ0&squot;s slice:&n;&t; */
id|wait_8254_wraparound
c_func
(paren
)paren
suffix:semicolon
id|__setup_APIC_LVTT
c_func
(paren
id|clocks
)paren
suffix:semicolon
id|t0
op_assign
id|apic_read
c_func
(paren
id|APIC_TMCCT
)paren
op_star
id|APIC_DIVISOR
suffix:semicolon
r_do
(brace
id|t1
op_assign
id|apic_read
c_func
(paren
id|APIC_TMCCT
)paren
op_star
id|APIC_DIVISOR
suffix:semicolon
id|delta
op_assign
(paren
r_int
)paren
(paren
id|t0
op_minus
id|t1
op_minus
id|slice
op_star
id|nr
)paren
suffix:semicolon
)brace
r_while
c_loop
(paren
id|delta
OL
l_int|0
)paren
suffix:semicolon
id|__setup_APIC_LVTT
c_func
(paren
id|clocks
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;CPU%d&lt;C0:%d,C:%d,D:%d,S:%d,C:%d&gt;&bslash;n&quot;
comma
id|smp_processor_id
c_func
(paren
)paren
comma
id|t0
comma
id|t1
comma
id|delta
comma
id|slice
comma
id|clocks
)paren
suffix:semicolon
id|__restore_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * In this function we calibrate APIC bus clocks to the external&n; * timer. Unfortunately we cannot use jiffies and the timer irq&n; * to calibrate, since some later bootup code depends on getting&n; * the first irq? Ugh.&n; *&n; * We want to do the calibration only once since we&n; * want to have local timer irqs syncron. CPUs connected&n; * by the same APIC bus have the very same bus frequency.&n; * And we want to have irqs off anyways, no accidental&n; * APIC irq that way.&n; */
DECL|function|calibrate_APIC_clock
r_int
id|__init
id|calibrate_APIC_clock
c_func
(paren
r_void
)paren
(brace
r_int
r_int
r_int
id|t1
op_assign
l_int|0
comma
id|t2
op_assign
l_int|0
suffix:semicolon
r_int
id|tt1
comma
id|tt2
suffix:semicolon
r_int
id|result
suffix:semicolon
r_int
id|i
suffix:semicolon
r_const
r_int
id|LOOPS
op_assign
id|HZ
op_div
l_int|10
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;calibrating APIC timer ... &quot;
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Put whatever arbitrary (but long enough) timeout&n;&t; * value into the APIC clock, we just want to get the&n;&t; * counter running for calibration.&n;&t; */
id|__setup_APIC_LVTT
c_func
(paren
l_int|1000000000
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * The timer chip counts down to zero. Let&squot;s wait&n;&t; * for a wraparound to start exact measurement:&n;&t; * (the current tick might have been already half done)&n;&t; */
id|wait_8254_wraparound
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * We wrapped around just now. Let&squot;s start:&n;&t; */
r_if
c_cond
(paren
id|cpu_has_tsc
)paren
id|rdtscll
c_func
(paren
id|t1
)paren
suffix:semicolon
id|tt1
op_assign
id|apic_read
c_func
(paren
id|APIC_TMCCT
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Let&squot;s wait LOOPS wraprounds:&n;&t; */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|LOOPS
suffix:semicolon
id|i
op_increment
)paren
id|wait_8254_wraparound
c_func
(paren
)paren
suffix:semicolon
id|tt2
op_assign
id|apic_read
c_func
(paren
id|APIC_TMCCT
)paren
suffix:semicolon
r_if
c_cond
(paren
id|cpu_has_tsc
)paren
id|rdtscll
c_func
(paren
id|t2
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * The APIC bus clock counter is 32 bits only, it&n;&t; * might have overflown, but note that we use signed&n;&t; * longs, thus no extra care needed.&n;&t; *&n;&t; * underflown to be exact, as the timer counts down ;)&n;&t; */
id|result
op_assign
(paren
id|tt1
op_minus
id|tt2
)paren
op_star
id|APIC_DIVISOR
op_div
id|LOOPS
suffix:semicolon
r_if
c_cond
(paren
id|cpu_has_tsc
)paren
id|printk
c_func
(paren
l_string|&quot;&bslash;n..... CPU clock speed is %ld.%04ld MHz.&bslash;n&quot;
comma
(paren
(paren
r_int
)paren
(paren
id|t2
op_minus
id|t1
)paren
op_div
id|LOOPS
)paren
op_div
(paren
l_int|1000000
op_div
id|HZ
)paren
comma
(paren
(paren
r_int
)paren
(paren
id|t2
op_minus
id|t1
)paren
op_div
id|LOOPS
)paren
op_mod
(paren
l_int|1000000
op_div
id|HZ
)paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;..... host bus clock speed is %ld.%04ld MHz.&bslash;n&quot;
comma
id|result
op_div
(paren
l_int|1000000
op_div
id|HZ
)paren
comma
id|result
op_mod
(paren
l_int|1000000
op_div
id|HZ
)paren
)paren
suffix:semicolon
r_return
id|result
suffix:semicolon
)brace
DECL|variable|calibration_result
r_static
r_int
r_int
id|calibration_result
suffix:semicolon
DECL|function|setup_APIC_clocks
r_void
id|__init
id|setup_APIC_clocks
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
id|__save_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__cli
c_func
(paren
)paren
suffix:semicolon
id|calibration_result
op_assign
id|calibrate_APIC_clock
c_func
(paren
)paren
suffix:semicolon
id|smp_call_function
c_func
(paren
id|setup_APIC_timer
comma
(paren
r_void
op_star
)paren
id|calibration_result
comma
l_int|1
comma
l_int|1
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Now set up the timer for real.&n;&t; */
id|setup_APIC_timer
c_func
(paren
(paren
r_void
op_star
)paren
id|calibration_result
)paren
suffix:semicolon
id|__restore_flags
c_func
(paren
id|flags
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * the frequency of the profiling timer can be changed&n; * by writing a multiplier value into /proc/profile.&n; */
DECL|function|setup_profiling_timer
r_int
id|setup_profiling_timer
c_func
(paren
r_int
r_int
id|multiplier
)paren
(brace
r_int
id|i
suffix:semicolon
multiline_comment|/*&n;&t; * Sanity check. [at least 500 APIC cycles should be&n;&t; * between APIC interrupts as a rule of thumb, to avoid&n;&t; * irqs flooding us]&n;&t; */
r_if
c_cond
(paren
(paren
op_logical_neg
id|multiplier
)paren
op_logical_or
(paren
id|calibration_result
op_div
id|multiplier
OL
l_int|500
)paren
)paren
r_return
op_minus
id|EINVAL
suffix:semicolon
multiline_comment|/* &n;&t; * Set the new multiplier for each CPU. CPUs don&squot;t start using the&n;&t; * new values until the next timer interrupt in which they do process&n;&t; * accounting. At that time they also adjust their APIC timers&n;&t; * accordingly.&n;&t; */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|NR_CPUS
suffix:semicolon
op_increment
id|i
)paren
id|prof_multiplier
(braket
id|i
)braket
op_assign
id|multiplier
suffix:semicolon
r_return
l_int|0
suffix:semicolon
)brace
DECL|macro|APIC_DIVISOR
macro_line|#undef APIC_DIVISOR
multiline_comment|/*&n; * Local timer interrupt handler. It does both profiling and&n; * process statistics/rescheduling.&n; *&n; * We do profiling in every local tick, statistics/rescheduling&n; * happen only every &squot;profiling multiplier&squot; ticks. The default&n; * multiplier is 1 and it can be changed by writing the new multiplier&n; * value into /proc/profile.&n; */
DECL|function|smp_local_timer_interrupt
r_inline
r_void
id|smp_local_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
op_star
id|regs
)paren
(brace
r_int
id|user
op_assign
(paren
id|user_mode
c_func
(paren
id|regs
)paren
op_ne
l_int|0
)paren
suffix:semicolon
r_int
id|cpu
op_assign
id|smp_processor_id
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * The profiling function is SMP safe. (nothing can mess&n;&t; * around with &quot;current&quot;, and the profiling counters are&n;&t; * updated with atomic operations). This is especially&n;&t; * useful with a profiling multiplier != 1&n;&t; */
r_if
c_cond
(paren
op_logical_neg
id|user
)paren
id|x86_do_profile
c_func
(paren
id|regs-&gt;eip
)paren
suffix:semicolon
r_if
c_cond
(paren
op_decrement
id|prof_counter
(braket
id|cpu
)braket
op_le
l_int|0
)paren
(brace
r_int
id|system
op_assign
l_int|1
op_minus
id|user
suffix:semicolon
r_struct
id|task_struct
op_star
id|p
op_assign
id|current
suffix:semicolon
multiline_comment|/*&n;&t;&t; * The multiplier may have changed since the last time we got&n;&t;&t; * to this point as a result of the user writing to&n;&t;&t; * /proc/profile. In this case we need to adjust the APIC&n;&t;&t; * timer accordingly.&n;&t;&t; *&n;&t;&t; * Interrupts are already masked off at this point.&n;&t;&t; */
id|prof_counter
(braket
id|cpu
)braket
op_assign
id|prof_multiplier
(braket
id|cpu
)braket
suffix:semicolon
r_if
c_cond
(paren
id|prof_counter
(braket
id|cpu
)braket
op_ne
id|prof_old_multiplier
(braket
id|cpu
)braket
)paren
(brace
id|__setup_APIC_LVTT
c_func
(paren
id|calibration_result
op_div
id|prof_counter
(braket
id|cpu
)braket
)paren
suffix:semicolon
id|prof_old_multiplier
(braket
id|cpu
)braket
op_assign
id|prof_counter
(braket
id|cpu
)braket
suffix:semicolon
)brace
multiline_comment|/*&n;&t;&t; * After doing the above, we need to make like&n;&t;&t; * a normal interrupt - otherwise timer interrupts&n;&t;&t; * ignore the global interrupt lock, which is the&n;&t;&t; * WrongThing (tm) to do.&n;&t;&t; */
id|irq_enter
c_func
(paren
id|cpu
comma
l_int|0
)paren
suffix:semicolon
id|update_one_process
c_func
(paren
id|p
comma
l_int|1
comma
id|user
comma
id|system
comma
id|cpu
)paren
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;pid
)paren
(brace
id|p-&gt;counter
op_sub_assign
l_int|1
suffix:semicolon
r_if
c_cond
(paren
id|p-&gt;counter
op_le
l_int|0
)paren
(brace
id|p-&gt;counter
op_assign
l_int|0
suffix:semicolon
id|p-&gt;need_resched
op_assign
l_int|1
suffix:semicolon
)brace
r_if
c_cond
(paren
id|p-&gt;priority
OL
id|DEF_PRIORITY
)paren
(brace
id|kstat.cpu_nice
op_add_assign
id|user
suffix:semicolon
id|kstat.per_cpu_nice
(braket
id|cpu
)braket
op_add_assign
id|user
suffix:semicolon
)brace
r_else
(brace
id|kstat.cpu_user
op_add_assign
id|user
suffix:semicolon
id|kstat.per_cpu_user
(braket
id|cpu
)braket
op_add_assign
id|user
suffix:semicolon
)brace
id|kstat.cpu_system
op_add_assign
id|system
suffix:semicolon
id|kstat.per_cpu_system
(braket
id|cpu
)braket
op_add_assign
id|system
suffix:semicolon
)brace
id|irq_exit
c_func
(paren
id|cpu
comma
l_int|0
)paren
suffix:semicolon
)brace
multiline_comment|/*&n;&t; * We take the &squot;long&squot; return path, and there every subsystem&n;&t; * grabs the apropriate locks (kernel lock/ irq lock).&n;&t; *&n;&t; * we might want to decouple profiling from the &squot;long path&squot;,&n;&t; * and do the profiling totally in assembly.&n;&t; *&n;&t; * Currently this isn&squot;t too much of an issue (performance wise),&n;&t; * we can take more than 100K local irqs per second on a 100 MHz P5.&n;&t; */
)brace
multiline_comment|/*&n; * Local APIC timer interrupt. This is the most natural way for doing&n; * local interrupts, but local timer interrupts can be emulated by&n; * broadcast interrupts too. [in case the hw doesnt support APIC timers]&n; *&n; * [ if a single-CPU system runs an SMP kernel then we call the local&n; *   interrupt as well. Thus we cannot inline the local irq ... ]&n; */
DECL|variable|apic_timer_irqs
r_int
r_int
id|apic_timer_irqs
(braket
id|NR_CPUS
)braket
op_assign
(brace
l_int|0
comma
)brace
suffix:semicolon
DECL|function|smp_apic_timer_interrupt
r_void
id|smp_apic_timer_interrupt
c_func
(paren
r_struct
id|pt_regs
op_star
id|regs
)paren
(brace
multiline_comment|/*&n;&t; * the NMI deadlock-detector uses this.&n;&t; */
id|apic_timer_irqs
(braket
id|smp_processor_id
c_func
(paren
)paren
)braket
op_increment
suffix:semicolon
multiline_comment|/*&n;&t; * NOTE! We&squot;d better ACK the irq immediately,&n;&t; * because timer handling can be slow.&n;&t; */
id|ack_APIC_irq
c_func
(paren
)paren
suffix:semicolon
id|smp_local_timer_interrupt
c_func
(paren
id|regs
)paren
suffix:semicolon
)brace
eof
