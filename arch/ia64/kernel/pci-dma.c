multiline_comment|/*&n; * Dynamic DMA mapping support.&n; *&n; * This implementation is for IA-64 platforms that do not support&n; * I/O TLBs (aka DMA address translation hardware).&n; * Copyright (C) 2000 Asit Mallick &lt;Asit.K.Mallick@intel.com&gt;&n; * Copyright (C) 2000 Goutham Rao &lt;goutham.rao@intel.com&gt;&n; */
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/pci.h&gt;
macro_line|#include &lt;linux/spinlock.h&gt;
macro_line|#include &lt;linux/string.h&gt;
macro_line|#include &lt;linux/types.h&gt;
macro_line|#include &lt;asm/io.h&gt;
macro_line|#include &lt;asm/pci.h&gt;
macro_line|#include &lt;asm/dma.h&gt;
macro_line|#ifdef CONFIG_SWIOTLB
macro_line|#include &lt;linux/init.h&gt;
macro_line|#include &lt;linux/bootmem.h&gt;
DECL|macro|ALIGN
mdefine_line|#define ALIGN(val, align) ((unsigned long) (((unsigned long) (val) + ((align) - 1)) &amp; ~((align) - 1)))
multiline_comment|/*&n; * log of the size of each IO TLB slab.  The number of slabs is command line&n; * controllable.&n; */
DECL|macro|IO_TLB_SHIFT
mdefine_line|#define IO_TLB_SHIFT 11
multiline_comment|/*&n; * Used to do a quick range check in pci_unmap_single and pci_sync_single, to see if the &n; * memory was in fact allocated by this API.&n; */
DECL|variable|io_tlb_start
DECL|variable|io_tlb_end
r_static
r_char
op_star
id|io_tlb_start
comma
op_star
id|io_tlb_end
suffix:semicolon
multiline_comment|/*&n; * The number of IO TLB blocks (in groups of 64) betweeen io_tlb_start and io_tlb_end.&n; * This is command line adjustable via setup_io_tlb_npages.&n; */
DECL|variable|io_tlb_nslabs
r_int
r_int
id|io_tlb_nslabs
op_assign
l_int|1024
suffix:semicolon
multiline_comment|/*&n; * This is a free list describing the number of free entries available from each index&n; */
DECL|variable|io_tlb_list
r_static
r_int
r_int
op_star
id|io_tlb_list
suffix:semicolon
DECL|variable|io_tlb_index
r_static
r_int
r_int
id|io_tlb_index
suffix:semicolon
multiline_comment|/*&n; * We need to save away the original address corresponding to a mapped entry for the sync &n; * operations.&n; */
DECL|variable|io_tlb_orig_addr
r_static
r_int
r_char
op_star
op_star
id|io_tlb_orig_addr
suffix:semicolon
multiline_comment|/*&n; * Protect the above data structures in the map and unmap calls&n; */
DECL|variable|io_tlb_lock
id|spinlock_t
id|io_tlb_lock
op_assign
id|SPIN_LOCK_UNLOCKED
suffix:semicolon
r_static
r_int
id|__init
DECL|function|setup_io_tlb_npages
id|setup_io_tlb_npages
(paren
r_char
op_star
id|str
)paren
(brace
id|io_tlb_nslabs
op_assign
id|simple_strtoul
c_func
(paren
id|str
comma
l_int|NULL
comma
l_int|0
)paren
op_lshift
(paren
id|PAGE_SHIFT
op_minus
id|IO_TLB_SHIFT
)paren
suffix:semicolon
r_return
l_int|1
suffix:semicolon
)brace
id|__setup
c_func
(paren
l_string|&quot;swiotlb=&quot;
comma
id|setup_io_tlb_npages
)paren
suffix:semicolon
multiline_comment|/*&n; * Statically reserve bounce buffer space and initialize bounce buffer&n; * data structures for the software IO TLB used to implement the PCI DMA API&n; */
r_void
DECL|function|setup_swiotlb
id|setup_swiotlb
(paren
r_void
)paren
(brace
r_int
id|i
suffix:semicolon
multiline_comment|/*&n;&t; * Get IO TLB memory from the low pages&n;&t; */
id|io_tlb_start
op_assign
id|alloc_bootmem_low_pages
c_func
(paren
id|io_tlb_nslabs
op_star
(paren
l_int|1
op_lshift
id|IO_TLB_SHIFT
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|io_tlb_start
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
id|io_tlb_end
op_assign
id|io_tlb_start
op_plus
id|io_tlb_nslabs
op_star
(paren
l_int|1
op_lshift
id|IO_TLB_SHIFT
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Allocate and initialize the free list array.  This array is used&n;&t; * to find contiguous free memory regions of size 2^IO_TLB_SHIFT between&n;&t; * io_tlb_start and io_tlb_end.&n;&t; */
id|io_tlb_list
op_assign
id|alloc_bootmem
c_func
(paren
id|io_tlb_nslabs
op_star
r_sizeof
(paren
r_int
)paren
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|io_tlb_nslabs
suffix:semicolon
id|i
op_increment
)paren
id|io_tlb_list
(braket
id|i
)braket
op_assign
id|io_tlb_nslabs
op_minus
id|i
suffix:semicolon
id|io_tlb_index
op_assign
l_int|0
suffix:semicolon
id|io_tlb_orig_addr
op_assign
id|alloc_bootmem
c_func
(paren
id|io_tlb_nslabs
op_star
r_sizeof
(paren
r_char
op_star
)paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;Placing software IO TLB between 0x%p - 0x%p&bslash;n&quot;
comma
(paren
r_void
op_star
)paren
id|io_tlb_start
comma
(paren
r_void
op_star
)paren
id|io_tlb_end
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Allocates bounce buffer and returns its kernel virtual address.&n; */
r_static
r_void
op_star
DECL|function|__pci_map_single
id|__pci_map_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_char
op_star
id|buffer
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_char
op_star
id|dma_addr
suffix:semicolon
r_int
r_int
id|i
comma
id|nslots
comma
id|stride
comma
id|index
comma
id|wrap
suffix:semicolon
multiline_comment|/*&n;&t; * For mappings greater than a page size, we limit the stride (and hence alignment)&n;&t; * to a page size.&n;&t; */
id|nslots
op_assign
id|ALIGN
c_func
(paren
id|size
comma
l_int|1
op_lshift
id|IO_TLB_SHIFT
)paren
op_rshift
id|IO_TLB_SHIFT
suffix:semicolon
r_if
c_cond
(paren
id|size
OG
(paren
l_int|1
op_lshift
id|PAGE_SHIFT
)paren
)paren
id|stride
op_assign
(paren
l_int|1
op_lshift
(paren
id|PAGE_SHIFT
op_minus
id|IO_TLB_SHIFT
)paren
)paren
suffix:semicolon
r_else
id|stride
op_assign
id|nslots
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|nslots
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Find suitable number of IO TLB entries size that will fit this request and allocate a buffer&n;&t; * from that IO TLB pool.&n;&t; */
id|spin_lock_irqsave
c_func
(paren
op_amp
id|io_tlb_lock
comma
id|flags
)paren
suffix:semicolon
(brace
id|wrap
op_assign
id|index
op_assign
id|ALIGN
c_func
(paren
id|io_tlb_index
comma
id|stride
)paren
suffix:semicolon
r_do
(brace
multiline_comment|/*&n;&t;&t;&t; * If we find a slot that indicates we have &squot;nslots&squot; number of &n;&t;&t;&t; * contiguous buffers, we allocate the buffers from that slot and mark the&n;&t;&t;&t; * entries as &squot;0&squot; indicating unavailable.&n;&t;&t;&t; */
r_if
c_cond
(paren
id|io_tlb_list
(braket
id|index
)braket
op_ge
id|nslots
)paren
(brace
r_for
c_loop
(paren
id|i
op_assign
id|index
suffix:semicolon
id|i
OL
id|index
op_plus
id|nslots
suffix:semicolon
id|i
op_increment
)paren
id|io_tlb_list
(braket
id|i
)braket
op_assign
l_int|0
suffix:semicolon
id|dma_addr
op_assign
id|io_tlb_start
op_plus
(paren
id|index
op_lshift
id|IO_TLB_SHIFT
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t;&t; * Update the indices to avoid searching in the next round.&n;&t;&t;&t;&t; */
id|io_tlb_index
op_assign
(paren
id|index
op_plus
id|nslots
)paren
OL
id|io_tlb_nslabs
ques
c_cond
(paren
id|index
op_plus
id|nslots
)paren
suffix:colon
l_int|0
suffix:semicolon
r_goto
id|found
suffix:semicolon
)brace
id|index
op_add_assign
id|stride
suffix:semicolon
r_if
c_cond
(paren
id|index
op_ge
id|io_tlb_nslabs
)paren
id|index
op_assign
l_int|0
suffix:semicolon
)brace
r_while
c_loop
(paren
id|index
op_ne
id|wrap
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * XXX What is a suitable recovery mechanism here?  We cannot &n;&t;&t; * sleep because we are called from with in interrupts!&n;&t;&t; */
id|panic
c_func
(paren
l_string|&quot;__pci_map_single: could not allocate software IO TLB (%ld bytes)&quot;
comma
id|size
)paren
suffix:semicolon
id|found
suffix:colon
)brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|io_tlb_lock
comma
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Save away the mapping from the original address to the DMA address.  This is needed&n;&t; * when we sync the memory.  Then we sync the buffer if needed.&n;&t; */
id|io_tlb_orig_addr
(braket
id|index
)braket
op_assign
id|buffer
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_TODEVICE
op_logical_or
id|direction
op_eq
id|PCI_DMA_BIDIRECTIONAL
)paren
id|memcpy
c_func
(paren
id|dma_addr
comma
id|buffer
comma
id|size
)paren
suffix:semicolon
r_return
id|dma_addr
suffix:semicolon
)brace
multiline_comment|/*&n; * dma_addr is the kernel virtual address of the bounce buffer to unmap.&n; */
r_static
r_void
DECL|function|__pci_unmap_single
id|__pci_unmap_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_char
op_star
id|dma_addr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_int
r_int
id|flags
suffix:semicolon
r_int
id|i
comma
id|nslots
op_assign
id|ALIGN
c_func
(paren
id|size
comma
l_int|1
op_lshift
id|IO_TLB_SHIFT
)paren
op_rshift
id|IO_TLB_SHIFT
suffix:semicolon
r_int
id|index
op_assign
(paren
id|dma_addr
op_minus
id|io_tlb_start
)paren
op_rshift
id|IO_TLB_SHIFT
suffix:semicolon
r_char
op_star
id|buffer
op_assign
id|io_tlb_orig_addr
(braket
id|index
)braket
suffix:semicolon
multiline_comment|/*&n;&t; * First, sync the memory before unmapping the entry&n;&t; */
r_if
c_cond
(paren
(paren
id|direction
op_eq
id|PCI_DMA_FROMDEVICE
)paren
op_logical_or
(paren
id|direction
op_eq
id|PCI_DMA_BIDIRECTIONAL
)paren
)paren
multiline_comment|/*&n; &t; &t; * bounce... copy the data back into the original buffer&n;&t;  &t; * and delete the bounce buffer.&n; &t; &t; */
id|memcpy
c_func
(paren
id|buffer
comma
id|dma_addr
comma
id|size
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Return the buffer to the free list by setting the corresponding entries to indicate&n;&t; * the number of contigous entries available.  &n;&t; * While returning the entries to the free list, we merge the entries with slots below&n;&t; * and above the pool being returned.&n;&t; */
id|spin_lock_irqsave
c_func
(paren
op_amp
id|io_tlb_lock
comma
id|flags
)paren
suffix:semicolon
(brace
r_int
id|count
op_assign
(paren
(paren
id|index
op_plus
id|nslots
)paren
OL
id|io_tlb_nslabs
ques
c_cond
id|io_tlb_list
(braket
id|index
op_plus
id|nslots
)braket
suffix:colon
l_int|0
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * Step 1: return the slots to the free list, merging the slots with superceeding slots&n;&t;&t; */
r_for
c_loop
(paren
id|i
op_assign
id|index
op_plus
id|nslots
op_minus
l_int|1
suffix:semicolon
id|i
op_ge
id|index
suffix:semicolon
id|i
op_decrement
)paren
id|io_tlb_list
(braket
id|i
)braket
op_assign
op_increment
id|count
suffix:semicolon
multiline_comment|/*&n;&t;&t; * Step 2: merge the returned slots with the preceeding slots, if available (non zero)&n;&t;&t; */
r_for
c_loop
(paren
id|i
op_assign
id|index
op_minus
l_int|1
suffix:semicolon
(paren
id|i
op_ge
l_int|0
)paren
op_logical_and
id|io_tlb_list
(braket
id|i
)braket
suffix:semicolon
id|i
op_decrement
)paren
id|io_tlb_list
(braket
id|i
)braket
op_add_assign
id|io_tlb_list
(braket
id|index
)braket
suffix:semicolon
)brace
id|spin_unlock_irqrestore
c_func
(paren
op_amp
id|io_tlb_lock
comma
id|flags
)paren
suffix:semicolon
)brace
r_static
r_void
DECL|function|__pci_sync_single
id|__pci_sync_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_char
op_star
id|dma_addr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_int
id|index
op_assign
(paren
id|dma_addr
op_minus
id|io_tlb_start
)paren
op_rshift
id|IO_TLB_SHIFT
suffix:semicolon
r_char
op_star
id|buffer
op_assign
id|io_tlb_orig_addr
(braket
id|index
)braket
suffix:semicolon
multiline_comment|/*&n;  &t; * bounce... copy the data back into/from the original buffer&n;&t; * XXX How do you handle PCI_DMA_BIDIRECTIONAL here ?&n; &t; */
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_FROMDEVICE
)paren
id|memcpy
c_func
(paren
id|buffer
comma
id|dma_addr
comma
id|size
)paren
suffix:semicolon
r_else
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_TODEVICE
)paren
id|memcpy
c_func
(paren
id|dma_addr
comma
id|buffer
comma
id|size
)paren
suffix:semicolon
r_else
id|BUG
c_func
(paren
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Map a single buffer of the indicated size for DMA in streaming mode.&n; * The PCI address to use is returned.&n; *&n; * Once the device is given the dma address, the device owns this memory&n; * until either pci_unmap_single or pci_dma_sync_single is performed.&n; */
id|dma_addr_t
DECL|function|pci_map_single
id|pci_map_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_void
op_star
id|ptr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_int
r_int
id|pci_addr
op_assign
id|virt_to_phys
c_func
(paren
id|ptr
)paren
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Check if the PCI device can DMA to ptr... if so, just return ptr&n;&t; */
r_if
c_cond
(paren
(paren
id|pci_addr
op_amp
op_complement
id|hwdev-&gt;dma_mask
)paren
op_eq
l_int|0
)paren
multiline_comment|/*&n;&t;&t; * Device is bit capable of DMA&squot;ing to the&n;&t;&t; * buffer... just return the PCI address of ptr&n;&t;&t; */
r_return
id|pci_addr
suffix:semicolon
multiline_comment|/* &n;&t; * get a bounce buffer: &n;&t; */
id|pci_addr
op_assign
id|virt_to_phys
c_func
(paren
id|__pci_map_single
c_func
(paren
id|hwdev
comma
id|ptr
comma
id|size
comma
id|direction
)paren
)paren
suffix:semicolon
multiline_comment|/*&n;&t; * Ensure that the address returned is DMA&squot;ble:&n;&t; */
r_if
c_cond
(paren
(paren
id|pci_addr
op_amp
op_complement
id|hwdev-&gt;dma_mask
)paren
op_ne
l_int|0
)paren
id|panic
c_func
(paren
l_string|&quot;__pci_map_single: bounce buffer is not DMA&squot;ble&quot;
)paren
suffix:semicolon
r_return
id|pci_addr
suffix:semicolon
)brace
multiline_comment|/*&n; * Unmap a single streaming mode DMA translation.  The dma_addr and size&n; * must match what was provided for in a previous pci_map_single call.  All&n; * other usages are undefined.&n; *&n; * After this call, reads by the cpu to the buffer are guarenteed to see&n; * whatever the device wrote there.&n; */
r_void
DECL|function|pci_unmap_single
id|pci_unmap_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
id|dma_addr_t
id|pci_addr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_char
op_star
id|dma_addr
op_assign
id|phys_to_virt
c_func
(paren
id|pci_addr
)paren
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|dma_addr
op_ge
id|io_tlb_start
op_logical_and
id|dma_addr
OL
id|io_tlb_end
)paren
id|__pci_unmap_single
c_func
(paren
id|hwdev
comma
id|dma_addr
comma
id|size
comma
id|direction
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Make physical memory consistent for a single&n; * streaming mode DMA translation after a transfer.&n; *&n; * If you perform a pci_map_single() but wish to interrogate the&n; * buffer using the cpu, yet do not wish to teardown the PCI dma&n; * mapping, you must call this function before doing so.  At the&n; * next point you give the PCI dma address back to the card, the&n; * device again owns the buffer.&n; */
r_void
DECL|function|pci_dma_sync_single
id|pci_dma_sync_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
id|dma_addr_t
id|pci_addr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_char
op_star
id|dma_addr
op_assign
id|phys_to_virt
c_func
(paren
id|pci_addr
)paren
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_if
c_cond
(paren
id|dma_addr
op_ge
id|io_tlb_start
op_logical_and
id|dma_addr
OL
id|io_tlb_end
)paren
id|__pci_sync_single
c_func
(paren
id|hwdev
comma
id|dma_addr
comma
id|size
comma
id|direction
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Map a set of buffers described by scatterlist in streaming&n; * mode for DMA.  This is the scather-gather version of the&n; * above pci_map_single interface.  Here the scatter gather list&n; * elements are each tagged with the appropriate dma address&n; * and length.  They are obtained via sg_dma_{address,length}(SG).&n; *&n; * NOTE: An implementation may be able to use a smaller number of&n; *       DMA address/length pairs than there are SG table elements.&n; *       (for example via virtual mapping capabilities)&n; *       The routine returns the number of addr/length pairs actually&n; *       used, at most nents.&n; *&n; * Device ownership issues as mentioned above for pci_map_single are&n; * the same here.&n; */
r_int
DECL|function|pci_map_sg
id|pci_map_sg
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nelems
comma
r_int
id|direction
)paren
(brace
r_int
id|i
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|nelems
suffix:semicolon
id|i
op_increment
comma
id|sg
op_increment
)paren
(brace
id|sg-&gt;orig_address
op_assign
id|sg-&gt;address
suffix:semicolon
r_if
c_cond
(paren
(paren
id|virt_to_phys
c_func
(paren
id|sg-&gt;address
)paren
op_amp
op_complement
id|hwdev-&gt;dma_mask
)paren
op_ne
l_int|0
)paren
(brace
id|sg-&gt;address
op_assign
id|__pci_map_single
c_func
(paren
id|hwdev
comma
id|sg-&gt;address
comma
id|sg-&gt;length
comma
id|direction
)paren
suffix:semicolon
)brace
)brace
r_return
id|nelems
suffix:semicolon
)brace
multiline_comment|/*&n; * Unmap a set of streaming mode DMA translations.&n; * Again, cpu read rules concerning calls here are the same as for&n; * pci_unmap_single() above.&n; */
r_void
DECL|function|pci_unmap_sg
id|pci_unmap_sg
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nelems
comma
r_int
id|direction
)paren
(brace
r_int
id|i
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|nelems
suffix:semicolon
id|i
op_increment
comma
id|sg
op_increment
)paren
r_if
c_cond
(paren
id|sg-&gt;orig_address
op_ne
id|sg-&gt;address
)paren
(brace
id|__pci_unmap_single
c_func
(paren
id|hwdev
comma
id|sg-&gt;address
comma
id|sg-&gt;length
comma
id|direction
)paren
suffix:semicolon
id|sg-&gt;address
op_assign
id|sg-&gt;orig_address
suffix:semicolon
)brace
)brace
multiline_comment|/*&n; * Make physical memory consistent for a set of streaming mode DMA&n; * translations after a transfer.&n; *&n; * The same as pci_dma_sync_single but for a scatter-gather list,&n; * same rules and usage.&n; */
r_void
DECL|function|pci_dma_sync_sg
id|pci_dma_sync_sg
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nelems
comma
r_int
id|direction
)paren
(brace
r_int
id|i
suffix:semicolon
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|nelems
suffix:semicolon
id|i
op_increment
comma
id|sg
op_increment
)paren
r_if
c_cond
(paren
id|sg-&gt;orig_address
op_ne
id|sg-&gt;address
)paren
id|__pci_sync_single
c_func
(paren
id|hwdev
comma
id|sg-&gt;address
comma
id|sg-&gt;length
comma
id|direction
)paren
suffix:semicolon
)brace
macro_line|#else
multiline_comment|/*&n; * Map a single buffer of the indicated size for DMA in streaming mode.&n; * The 32-bit bus address to use is returned.&n; *&n; * Once the device is given the dma address, the device owns this memory&n; * until either pci_unmap_single or pci_dma_sync_single is performed.&n; */
id|dma_addr_t
DECL|function|pci_map_single
id|pci_map_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_void
op_star
id|ptr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_return
id|virt_to_bus
c_func
(paren
id|ptr
)paren
suffix:semicolon
)brace
multiline_comment|/*&n; * Unmap a single streaming mode DMA translation.  The dma_addr and size&n; * must match what was provided for in a previous pci_map_single call.  All&n; * other usages are undefined.&n; *&n; * After this call, reads by the cpu to the buffer are guarenteed to see&n; * whatever the device wrote there.&n; */
r_void
DECL|function|pci_unmap_single
id|pci_unmap_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
id|dma_addr_t
id|dma_addr
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Nothing to do */
)brace
multiline_comment|/*&n; * Map a set of buffers described by scatterlist in streaming&n; * mode for DMA.  This is the scather-gather version of the&n; * above pci_map_single interface.  Here the scatter gather list&n; * elements are each tagged with the appropriate dma address&n; * and length.  They are obtained via sg_dma_{address,length}(SG).&n; *&n; * NOTE: An implementation may be able to use a smaller number of&n; *       DMA address/length pairs than there are SG table elements.&n; *       (for example via virtual mapping capabilities)&n; *       The routine returns the number of addr/length pairs actually&n; *       used, at most nents.&n; *&n; * Device ownership issues as mentioned above for pci_map_single are&n; * the same here.&n; */
r_int
DECL|function|pci_map_sg
id|pci_map_sg
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nents
comma
r_int
id|direction
)paren
(brace
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
r_return
id|nents
suffix:semicolon
)brace
multiline_comment|/*&n; * Unmap a set of streaming mode DMA translations.&n; * Again, cpu read rules concerning calls here are the same as for&n; * pci_unmap_single() above.&n; */
r_void
DECL|function|pci_unmap_sg
id|pci_unmap_sg
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nents
comma
r_int
id|direction
)paren
(brace
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Nothing to do */
)brace
multiline_comment|/*&n; * Make physical memory consistent for a single&n; * streaming mode DMA translation after a transfer.&n; *&n; * If you perform a pci_map_single() but wish to interrogate the&n; * buffer using the cpu, yet do not wish to teardown the PCI dma&n; * mapping, you must call this function before doing so.  At the&n; * next point you give the PCI dma address back to the card, the&n; * device again owns the buffer.&n; */
r_void
DECL|function|pci_dma_sync_single
id|pci_dma_sync_single
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
id|dma_addr_t
id|dma_handle
comma
r_int
id|size
comma
r_int
id|direction
)paren
(brace
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Nothing to do */
)brace
multiline_comment|/*&n; * Make physical memory consistent for a set of streaming mode DMA&n; * translations after a transfer.&n; *&n; * The same as pci_dma_sync_single but for a scatter-gather list,&n; * same rules and usage.&n; */
r_void
DECL|function|pci_dma_sync_sg
id|pci_dma_sync_sg
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_struct
id|scatterlist
op_star
id|sg
comma
r_int
id|nelems
comma
r_int
id|direction
)paren
(brace
r_if
c_cond
(paren
id|direction
op_eq
id|PCI_DMA_NONE
)paren
id|BUG
c_func
(paren
)paren
suffix:semicolon
multiline_comment|/* Nothing to do */
)brace
macro_line|#endif /* CONFIG_SWIOTLB */
r_void
op_star
DECL|function|pci_alloc_consistent
id|pci_alloc_consistent
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_int
id|size
comma
id|dma_addr_t
op_star
id|dma_handle
)paren
(brace
r_int
r_int
id|pci_addr
suffix:semicolon
r_int
id|gfp
op_assign
id|GFP_ATOMIC
suffix:semicolon
r_void
op_star
id|ret
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|hwdev
op_logical_or
id|hwdev-&gt;dma_mask
op_le
l_int|0xffffffff
)paren
id|gfp
op_or_assign
id|GFP_DMA
suffix:semicolon
multiline_comment|/* XXX fix me: should change this to GFP_32BIT or ZONE_32BIT */
id|ret
op_assign
(paren
r_void
op_star
)paren
id|__get_free_pages
c_func
(paren
id|gfp
comma
id|get_order
c_func
(paren
id|size
)paren
)paren
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|ret
)paren
r_return
l_int|NULL
suffix:semicolon
id|memset
c_func
(paren
id|ret
comma
l_int|0
comma
id|size
)paren
suffix:semicolon
id|pci_addr
op_assign
id|virt_to_phys
c_func
(paren
id|ret
)paren
suffix:semicolon
r_if
c_cond
(paren
(paren
id|pci_addr
op_amp
op_complement
id|hwdev-&gt;dma_mask
)paren
op_ne
l_int|0
)paren
id|panic
c_func
(paren
l_string|&quot;pci_alloc_consistent: allocated memory is out of range for PCI device&quot;
)paren
suffix:semicolon
op_star
id|dma_handle
op_assign
id|pci_addr
suffix:semicolon
r_return
id|ret
suffix:semicolon
)brace
r_void
DECL|function|pci_free_consistent
id|pci_free_consistent
(paren
r_struct
id|pci_dev
op_star
id|hwdev
comma
r_int
id|size
comma
r_void
op_star
id|vaddr
comma
id|dma_addr_t
id|dma_handle
)paren
(brace
id|free_pages
c_func
(paren
(paren
r_int
r_int
)paren
id|vaddr
comma
id|get_order
c_func
(paren
id|size
)paren
)paren
suffix:semicolon
)brace
eof
