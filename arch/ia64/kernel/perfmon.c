multiline_comment|/*&n; * This file contains the code to configure and read/write the ia64 performance&n; * monitoring stuff.&n; *&n; * Originaly Written by Ganesh Venkitachalam, IBM Corp.&n; * Modifications by David Mosberger-Tang, Hewlett-Packard Co.&n; * Copyright (C) 1999 Ganesh Venkitachalam &lt;venkitac@us.ibm.com&gt;&n; * Copyright (C) 1999 David Mosberger-Tang &lt;davidm@hpl.hp.com&gt;&n; */
macro_line|#include &lt;linux/config.h&gt;
macro_line|#include &lt;linux/kernel.h&gt;
macro_line|#include &lt;linux/sched.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
macro_line|#include &lt;asm/errno.h&gt;
macro_line|#include &lt;asm/hw_irq.h&gt;
macro_line|#include &lt;asm/processor.h&gt;
macro_line|#include &lt;asm/system.h&gt;
macro_line|#include &lt;asm/uaccess.h&gt;
multiline_comment|/* Long blurb on how this works: &n; * We set dcr.pp, psr.pp, and the appropriate pmc control values with&n; * this.  Notice that we go about modifying _each_ task&squot;s pt_regs to&n; * set cr_ipsr.pp.  This will start counting when &quot;current&quot; does an&n; * _rfi_. Also, since each task&squot;s cr_ipsr.pp, and cr_ipsr is inherited&n; * across forks, we do _not_ need additional code on context&n; * switches. On stopping of the counters we dont need to go about&n; * changing every task&squot;s cr_ipsr back to where it wuz, because we can&n; * just set pmc[0]=1. But we do it anyways becuase we will probably&n; * add thread specific accounting later.&n; *&n; * The obvious problem with this is that on SMP systems, it is a bit&n; * of work (when someone wants to do it:-)) - it would be easier if we&n; * just added code to the context-switch path, but if we wanted to support&n; * per-thread accounting, the context-switch path might be long unless &n; * we introduce a flag in the task_struct. Right now, the following code &n; * will NOT work correctly on MP (for more than one reason:-)).&n; *&n; * The short answer is that to make this work on SMP,  we would need &n; * to lock the run queue to ensure no context switches, send &n; * an IPI to each processor, and in that IPI handler, set processor regs,&n; * and just modify the psr bit of only the _current_ thread, since we have &n; * modified the psr bit correctly in the kernel stack for every process &n; * which is not running. Also, we need pmd arrays per-processor, and &n; * the READ_PMD command will need to get values off of other processors. &n; * IPIs are the answer, irrespective of what the question is. Might &n; * crash on SMP systems without the lock_kernel().&n; */
macro_line|#ifdef CONFIG_PERFMON
DECL|macro|MAX_PERF_COUNTER
mdefine_line|#define MAX_PERF_COUNTER&t;4&t;/* true for Itanium, at least */
DECL|macro|WRITE_PMCS_AND_START
mdefine_line|#define WRITE_PMCS_AND_START&t;0xa0
DECL|macro|WRITE_PMCS
mdefine_line|#define WRITE_PMCS&t;&t;0xa1
DECL|macro|READ_PMDS
mdefine_line|#define READ_PMDS&t;&t;0xa2
DECL|macro|STOP_PMCS
mdefine_line|#define STOP_PMCS&t;&t;0xa3
DECL|macro|IA64_COUNTER_MASK
mdefine_line|#define IA64_COUNTER_MASK&t;0xffffffffffffff6f
DECL|macro|PERF_OVFL_VAL
mdefine_line|#define PERF_OVFL_VAL&t;&t;0xffffffff
DECL|struct|perfmon_counter
r_struct
id|perfmon_counter
(brace
DECL|member|data
r_int
r_int
id|data
suffix:semicolon
DECL|member|counter_num
r_int
r_int
id|counter_num
suffix:semicolon
)brace
suffix:semicolon
DECL|variable|pmds
r_int
r_int
id|pmds
(braket
id|MAX_PERF_COUNTER
)braket
suffix:semicolon
DECL|variable|perf_owner
r_struct
id|task_struct
op_star
id|perf_owner
op_assign
l_int|NULL
suffix:semicolon
id|asmlinkage
r_int
r_int
DECL|function|sys_perfmonctl
id|sys_perfmonctl
(paren
r_int
id|cmd1
comma
r_int
id|cmd2
comma
r_void
op_star
id|ptr
)paren
(brace
r_struct
id|perfmon_counter
id|tmp
comma
op_star
id|cptr
op_assign
id|ptr
suffix:semicolon
r_int
r_int
id|pmd
comma
id|cnum
comma
id|dcr
comma
id|flags
suffix:semicolon
r_struct
id|task_struct
op_star
id|p
suffix:semicolon
r_struct
id|pt_regs
op_star
id|regs
suffix:semicolon
r_struct
id|perf_counter
suffix:semicolon
r_int
id|i
suffix:semicolon
r_switch
c_cond
(paren
id|cmd1
)paren
(brace
r_case
id|WRITE_PMCS
suffix:colon
multiline_comment|/* Writes to PMC&squot;s and clears PMDs */
r_case
id|WRITE_PMCS_AND_START
suffix:colon
multiline_comment|/* Also starts counting */
r_if
c_cond
(paren
op_logical_neg
id|access_ok
c_func
(paren
id|VERIFY_READ
comma
id|cptr
comma
r_sizeof
(paren
r_struct
id|perf_counter
)paren
op_star
id|cmd2
)paren
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
r_if
c_cond
(paren
id|cmd2
OG
id|MAX_PERF_COUNTER
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
r_if
c_cond
(paren
id|perf_owner
op_logical_and
id|perf_owner
op_ne
id|current
)paren
r_return
op_minus
id|EBUSY
suffix:semicolon
id|perf_owner
op_assign
id|current
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|cmd2
suffix:semicolon
id|i
op_increment
comma
id|cptr
op_increment
)paren
(brace
id|copy_from_user
c_func
(paren
op_amp
id|tmp
comma
id|cptr
comma
r_sizeof
(paren
id|tmp
)paren
)paren
suffix:semicolon
multiline_comment|/* XXX need to check validity of counter_num and perhaps data!! */
id|ia64_set_pmc
c_func
(paren
id|tmp.counter_num
comma
id|tmp.data
)paren
suffix:semicolon
id|ia64_set_pmd
c_func
(paren
id|tmp.counter_num
comma
l_int|0
)paren
suffix:semicolon
id|pmds
(braket
id|tmp.counter_num
op_minus
l_int|4
)braket
op_assign
l_int|0
suffix:semicolon
)brace
r_if
c_cond
(paren
id|cmd1
op_eq
id|WRITE_PMCS_AND_START
)paren
(brace
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|dcr
op_assign
id|ia64_get_dcr
c_func
(paren
)paren
suffix:semicolon
id|dcr
op_or_assign
id|IA64_DCR_PP
suffix:semicolon
id|ia64_set_dcr
c_func
(paren
id|dcr
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t;&t; * This is a no can do.  It obviously wouldn&squot;t&n;&t;&t;&t; * work on SMP where another process may not&n;&t;&t;&t; * be blocked at all. We need to put in a  perfmon &n;&t;&t;&t; * IPI to take care of MP systems. See blurb above.&n;&t;&t;&t; */
id|lock_kernel
c_func
(paren
)paren
suffix:semicolon
id|for_each_task
c_func
(paren
id|p
)paren
(brace
id|regs
op_assign
(paren
r_struct
id|pt_regs
op_star
)paren
(paren
(paren
(paren
r_char
op_star
)paren
id|p
)paren
op_plus
id|IA64_STK_OFFSET
)paren
op_minus
l_int|1
suffix:semicolon
id|ia64_psr
c_func
(paren
id|regs
)paren
op_member_access_from_pointer
id|pp
op_assign
l_int|1
suffix:semicolon
)brace
id|unlock_kernel
c_func
(paren
)paren
suffix:semicolon
id|ia64_set_pmc
c_func
(paren
l_int|0
comma
l_int|0
)paren
suffix:semicolon
)brace
r_break
suffix:semicolon
r_case
id|READ_PMDS
suffix:colon
r_if
c_cond
(paren
id|cmd2
OG
id|MAX_PERF_COUNTER
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
r_if
c_cond
(paren
op_logical_neg
id|access_ok
c_func
(paren
id|VERIFY_WRITE
comma
id|cptr
comma
r_sizeof
(paren
r_struct
id|perf_counter
)paren
op_star
id|cmd2
)paren
)paren
r_return
op_minus
id|EFAULT
suffix:semicolon
multiline_comment|/* This looks shady, but IMHO this will work fine. This is  &n;&t;&t; * the sequence that I could come up with to avoid races&n;&t;&t; * with the interrupt handler. See explanation in the &n;&t;&t; * following comment.&n;&t;&t; */
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__asm__
id|__volatile__
c_func
(paren
l_string|&quot;rsm psr.pp&bslash;n&quot;
)paren
suffix:semicolon
id|dcr
op_assign
id|ia64_get_dcr
c_func
(paren
)paren
suffix:semicolon
id|dcr
op_and_assign
op_complement
id|IA64_DCR_PP
suffix:semicolon
id|ia64_set_dcr
c_func
(paren
id|dcr
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * We cannot write to pmc[0] to stop counting here, as&n;&t;&t; * that particular instruction might cause an overflow&n;&t;&t; * and the mask in pmc[0] might get lost. I&squot;m _not_ &n;&t;&t; * sure of the hardware behavior here. So we stop&n;&t;&t; * counting by psr.pp = 0. And we reset dcr.pp to&n;&t;&t; * prevent an interrupt from mucking up psr.pp in the&n;&t;&t; * meanwhile. Perfmon interrupts are pended, hence the&n;&t;&t; * above code should be ok if one of the above instructions &n;&t;&t; * caused overflows, i.e the interrupt should get serviced&n;&t;&t; * when we re-enabled interrupts. When I muck with dcr, &n;&t;&t; * is the irq_save/restore needed?&n;&t;&t; */
r_for
c_loop
(paren
id|i
op_assign
l_int|0
comma
id|cnum
op_assign
l_int|4
suffix:semicolon
id|i
OL
id|MAX_PERF_COUNTER
suffix:semicolon
id|i
op_increment
comma
id|cnum
op_increment
comma
id|cptr
op_increment
)paren
(brace
id|pmd
op_assign
id|pmds
(braket
id|i
)braket
op_plus
(paren
id|ia64_get_pmd
c_func
(paren
id|cnum
)paren
op_amp
id|PERF_OVFL_VAL
)paren
suffix:semicolon
id|put_user
c_func
(paren
id|pmd
comma
op_amp
id|cptr-&gt;data
)paren
suffix:semicolon
)brace
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|__asm__
id|__volatile__
c_func
(paren
l_string|&quot;ssm psr.pp&quot;
)paren
suffix:semicolon
id|dcr
op_assign
id|ia64_get_dcr
c_func
(paren
)paren
suffix:semicolon
id|dcr
op_or_assign
id|IA64_DCR_PP
suffix:semicolon
id|ia64_set_dcr
c_func
(paren
id|dcr
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
r_break
suffix:semicolon
r_case
id|STOP_PMCS
suffix:colon
id|ia64_set_pmc
c_func
(paren
l_int|0
comma
l_int|1
)paren
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
suffix:semicolon
id|i
OL
id|MAX_PERF_COUNTER
suffix:semicolon
op_increment
id|i
)paren
id|ia64_set_pmc
c_func
(paren
id|i
comma
l_int|0
)paren
suffix:semicolon
id|local_irq_save
c_func
(paren
id|flags
)paren
suffix:semicolon
id|dcr
op_assign
id|ia64_get_dcr
c_func
(paren
)paren
suffix:semicolon
id|dcr
op_and_assign
op_complement
id|IA64_DCR_PP
suffix:semicolon
id|ia64_set_dcr
c_func
(paren
id|dcr
)paren
suffix:semicolon
id|local_irq_restore
c_func
(paren
id|flags
)paren
suffix:semicolon
multiline_comment|/*&n;&t;&t; * This is a no can do.  It obviously wouldn&squot;t&n;&t;&t; * work on SMP where another process may not&n;&t;&t; * be blocked at all. We need to put in a  perfmon &n;&t;&t; * IPI to take care of MP systems. See blurb above.&n;&t;&t; */
id|lock_kernel
c_func
(paren
)paren
suffix:semicolon
id|for_each_task
c_func
(paren
id|p
)paren
(brace
id|regs
op_assign
(paren
r_struct
id|pt_regs
op_star
)paren
(paren
(paren
(paren
r_char
op_star
)paren
id|p
)paren
op_plus
id|IA64_STK_OFFSET
)paren
op_minus
l_int|1
suffix:semicolon
id|ia64_psr
c_func
(paren
id|regs
)paren
op_member_access_from_pointer
id|pp
op_assign
l_int|0
suffix:semicolon
)brace
id|unlock_kernel
c_func
(paren
)paren
suffix:semicolon
id|perf_owner
op_assign
l_int|NULL
suffix:semicolon
r_break
suffix:semicolon
r_default
suffix:colon
r_break
suffix:semicolon
)brace
r_return
l_int|0
suffix:semicolon
)brace
r_static
r_inline
r_void
DECL|function|update_counters
id|update_counters
(paren
r_void
)paren
(brace
r_int
r_int
id|mask
comma
id|i
comma
id|cnum
comma
id|val
suffix:semicolon
id|mask
op_assign
id|ia64_get_pmc
c_func
(paren
l_int|0
)paren
op_rshift
l_int|4
suffix:semicolon
r_for
c_loop
(paren
id|i
op_assign
l_int|0
comma
id|cnum
op_assign
l_int|4
suffix:semicolon
id|i
OL
id|MAX_PERF_COUNTER
suffix:semicolon
id|cnum
op_increment
comma
id|i
op_increment
comma
id|mask
op_rshift_assign
l_int|1
)paren
(brace
r_if
c_cond
(paren
id|mask
op_amp
l_int|0x1
)paren
id|val
op_assign
id|PERF_OVFL_VAL
suffix:semicolon
r_else
multiline_comment|/* since we got an interrupt, might as well clear every pmd. */
id|val
op_assign
id|ia64_get_pmd
c_func
(paren
id|cnum
)paren
op_amp
id|PERF_OVFL_VAL
suffix:semicolon
id|pmds
(braket
id|i
)braket
op_add_assign
id|val
suffix:semicolon
id|ia64_set_pmd
c_func
(paren
id|cnum
comma
l_int|0
)paren
suffix:semicolon
)brace
)brace
r_static
r_void
DECL|function|perfmon_interrupt
id|perfmon_interrupt
(paren
r_int
id|irq
comma
r_void
op_star
id|arg
comma
r_struct
id|pt_regs
op_star
id|regs
)paren
(brace
id|update_counters
c_func
(paren
)paren
suffix:semicolon
id|ia64_set_pmc
c_func
(paren
l_int|0
comma
l_int|0
)paren
suffix:semicolon
id|ia64_srlz_d
c_func
(paren
)paren
suffix:semicolon
)brace
r_void
DECL|function|perfmon_init
id|perfmon_init
(paren
r_void
)paren
(brace
r_if
c_cond
(paren
id|request_irq
c_func
(paren
id|PERFMON_IRQ
comma
id|perfmon_interrupt
comma
l_int|0
comma
l_string|&quot;perfmon&quot;
comma
l_int|NULL
)paren
)paren
(brace
id|printk
c_func
(paren
l_string|&quot;perfmon_init: could not allocate performance monitor vector %u&bslash;n&quot;
comma
id|PERFMON_IRQ
)paren
suffix:semicolon
r_return
suffix:semicolon
)brace
id|ia64_set_pmv
c_func
(paren
id|PERFMON_IRQ
)paren
suffix:semicolon
id|ia64_srlz_d
c_func
(paren
)paren
suffix:semicolon
id|printk
c_func
(paren
l_string|&quot;Initialized perfmon vector to %u&bslash;n&quot;
comma
id|PERFMON_IRQ
)paren
suffix:semicolon
)brace
macro_line|#else /* !CONFIG_PERFMON */
id|asmlinkage
r_int
r_int
DECL|function|sys_perfmonctl
id|sys_perfmonctl
(paren
r_int
id|cmd1
comma
r_int
id|cmd2
comma
r_void
op_star
id|ptr
)paren
(brace
r_return
op_minus
id|ENOSYS
suffix:semicolon
)brace
macro_line|#endif /* !CONFIG_PERFMON */
eof
