multiline_comment|/*&n; *&t;linux/kernel/softirq.c&n; *&n; *&t;Copyright (C) 1992 Linus Torvalds&n; *&n; * do_bottom_half() runs at normal kernel priority: all interrupts&n; * enabled.  do_bottom_half() is atomic with respect to itself: a&n; * bottom_half handler need not be re-entrant.&n; */
macro_line|#include &lt;linux/ptrace.h&gt;
macro_line|#include &lt;linux/errno.h&gt;
macro_line|#include &lt;linux/kernel_stat.h&gt;
macro_line|#include &lt;linux/signal.h&gt;
macro_line|#include &lt;linux/sched.h&gt;
macro_line|#include &lt;linux/interrupt.h&gt;
macro_line|#include &lt;linux/mm.h&gt;
macro_line|#include &lt;linux/smp.h&gt;
macro_line|#include &lt;linux/smp_lock.h&gt;
macro_line|#include &lt;asm/system.h&gt;
macro_line|#include &lt;asm/io.h&gt;
macro_line|#include &lt;asm/irq.h&gt;
macro_line|#include &lt;asm/bitops.h&gt;
macro_line|#include &lt;asm/atomic.h&gt;
DECL|variable|intr_count
id|atomic_t
id|intr_count
op_assign
l_int|0
suffix:semicolon
DECL|variable|bh_mask_count
r_int
id|bh_mask_count
(braket
l_int|32
)braket
suffix:semicolon
DECL|variable|bh_active
r_int
r_int
id|bh_active
op_assign
l_int|0
suffix:semicolon
DECL|variable|bh_mask
r_int
r_int
id|bh_mask
op_assign
l_int|0
suffix:semicolon
DECL|variable|bh_base
r_void
(paren
op_star
id|bh_base
(braket
l_int|32
)braket
)paren
(paren
r_void
)paren
suffix:semicolon
multiline_comment|/*&n; * This needs to make sure that only one bottom half handler&n; * is ever active at a time. We do this without locking by&n; * doing an atomic increment on the intr_count, and checking&n; * (nonatomically) against 1. Only if it&squot;s 1 do we schedule&n; * the bottom half.&n; *&n; * Note that the non-atomicity of the test (as opposed to the&n; * actual update) means that the test may fail, and _nobody_&n; * runs the handlers if there is a race that makes multiple&n; * CPU&squot;s get here at the same time. That&squot;s ok, we&squot;ll run them&n; * next time around.&n; */
DECL|function|run_bottom_halves
r_static
r_inline
r_void
id|run_bottom_halves
c_func
(paren
r_void
)paren
(brace
r_int
r_int
id|active
suffix:semicolon
r_int
r_int
id|mask
comma
id|left
suffix:semicolon
r_void
(paren
op_star
op_star
id|bh
)paren
(paren
r_void
)paren
suffix:semicolon
id|cli
c_func
(paren
)paren
suffix:semicolon
id|active
op_assign
id|bh_active
op_amp
id|bh_mask
suffix:semicolon
id|bh_active
op_and_assign
op_complement
id|active
suffix:semicolon
id|sti
c_func
(paren
)paren
suffix:semicolon
id|bh
op_assign
id|bh_base
suffix:semicolon
r_for
c_loop
(paren
id|mask
op_assign
l_int|1
comma
id|left
op_assign
op_complement
l_int|0
suffix:semicolon
id|left
op_amp
id|active
suffix:semicolon
id|bh
op_increment
comma
id|mask
op_add_assign
id|mask
comma
id|left
op_add_assign
id|left
)paren
(brace
r_if
c_cond
(paren
id|mask
op_amp
id|active
)paren
(brace
(paren
op_star
id|bh
)paren
(paren
)paren
suffix:semicolon
)brace
)brace
)brace
multiline_comment|/*&n; * We really shouldn&squot;t need to get the kernel lock here,&n; * but we do it the easy way for now (the scheduler gets&n; * upset if somebody messes with intr_count without having&n; * the kernel lock).&n; *&n; * Get rid of the kernel lock here at the same time we&n; * make interrupt handling sane. &n; */
DECL|function|do_bottom_half
id|asmlinkage
r_void
id|do_bottom_half
c_func
(paren
r_void
)paren
(brace
id|lock_kernel
c_func
(paren
)paren
suffix:semicolon
id|atomic_inc
c_func
(paren
op_amp
id|intr_count
)paren
suffix:semicolon
r_if
c_cond
(paren
id|intr_count
op_eq
l_int|1
)paren
id|run_bottom_halves
c_func
(paren
)paren
suffix:semicolon
id|atomic_dec
c_func
(paren
op_amp
id|intr_count
)paren
suffix:semicolon
id|unlock_kernel
c_func
(paren
)paren
suffix:semicolon
)brace
eof
